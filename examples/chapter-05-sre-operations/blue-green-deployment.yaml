# Blue-Green Deployment Configuration
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: llm-d-blue-green
  namespace: production
spec:
  replicas: 8
  strategy:
    blueGreen:
      # Reference to service that the rollout modifies as the active service
      activeService: llm-d-active
      # Pre-promotion analysis
      prePromotionAnalysis:
        templates:
        - templateName: success-rate
        args:
        - name: service-name
          value: llm-d-preview
      # Post-promotion analysis  
      postPromotionAnalysis:
        templates:
        - templateName: success-rate
        args:
        - name: service-name
          value: llm-d-active
      
      # Automatic promotion after 10 minutes if analysis passes
      autoPromotionEnabled: false
      scaleDownDelaySeconds: 30
      previewReplicaCount: 2
      
  selector:
    matchLabels:
      app: llm-d
  template:
    metadata:
      labels:
        app: llm-d
    spec:
      containers:
      - name: llm-d-service
        image: llm-d/service:v1.2.0
        ports:
        - containerPort: 8080
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "16Gi"
          requests:
            nvidia.com/gpu: 1
            memory: "16Gi"
        
        # Health checks
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3

---
# Analysis Template for Success Rate
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: success-rate
  namespace: production
spec:
  args:
  - name: service-name
  metrics:
  - name: success-rate
    interval: 60s
    count: 5
    successCondition: result[0] >= 0.95
    failureLimit: 3
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc.cluster.local:9090
        query: |
          sum(
            rate(llm_d_requests_total{service="{{args.service-name}}",status!~"5.."}[2m])
          ) /
          sum(
            rate(llm_d_requests_total{service="{{args.service-name}}"}[2m])
          )