# Works Cited

This appendix provides comprehensive references to the authoritative sources that define llm-d and support the technical content throughout this book. All sources are current as of the book's publication and represent the ground truth documentation for the llm-d project.

## Primary Project Documentation

### Core Project Specifications

**llm-d Project Overview**  
llm-d Community. *PROJECT.md - llm-d Core Project Documentation*. GitHub, 2024.  
<https://github.com/llm-d/llm-d/blob/dev/PROJECT.md>  
Accessed: July 16, 2025

**llm-d Technical Proposal**  
llm-d Community. *llm-d Technical Proposal and Architecture Specification*. GitHub, 2024.  
<https://github.com/llm-d/llm-d/blob/dev/docs/proposals/llm-d.md>  
Accessed: July 16, 2025

**llm-d Main Repository**  
llm-d Community. *llm-d: Kubernetes-native distributed inference serving stack*. GitHub, 2024.  
<https://github.com/llm-d/llm-d/blob/dev/README.md>  
Accessed: July 16, 2025

## Technical Components Documentation

### Core Infrastructure Components

**KV Cache Manager**  
llm-d Community. *llm-d-kv-cache-manager: High-performance KV cache management for distributed LLM inference*. GitHub, 2024.  
<https://github.com/llm-d/llm-d-kv-cache-manager/blob/main/README.md>  
Accessed: July 16, 2025

**Benchmark Framework**  
llm-d Community. *llm-d-benchmark: Automated workflow for benchmarking LLM inference performance*. GitHub, 2024.  
<https://github.com/llm-d/llm-d-benchmark/blob/main/README.md>  
Accessed: July 16, 2025

**Model Service Operator**  
llm-d Community. *llm-d-model-service: Kubernetes operator for ModelService management*. GitHub, 2024.  
<https://github.com/llm-d/llm-d-model-service/blob/main/README.md>  
Accessed: July 16, 2025

### Deployment and Operations

**Platform Deployer**  
llm-d Community. *llm-d-deployer: Helm-based deployment framework for llm-d platform*. GitHub, 2024.  
<https://github.com/llm-d/llm-d-deployer/blob/main/README.md>  
Accessed: July 16, 2025

**Quickstart Guide**  
llm-d Community. *llm-d Quickstart Installation Guide*. GitHub, 2024.  
<https://github.com/llm-d/llm-d-deployer/blob/main/quickstart/README.md>  
Accessed: July 16, 2025

**Inference Scheduler**  
llm-d Community. *llm-d-inference-scheduler: Optimized routing for inference requests*. GitHub, 2024.  
<https://github.com/llm-d/llm-d-inference-scheduler/blob/main/README.md>  
Accessed: July 16, 2025

### Development and Testing Tools

**Inference Simulator**  
llm-d Community. *llm-d-inference-sim: vLLM simulator for development and testing*. GitHub, 2024.  
<https://github.com/llm-d/llm-d-inference-sim/blob/main/README.md>  
Accessed: July 16, 2025

**Routing Sidecar**  
llm-d Community. *llm-d-routing-sidecar: Experimental reverse proxy for P/D disaggregation*. GitHub, 2024.  
<https://github.com/llm-d/llm-d-routing-sidecar/blob/main/README.md>  
Accessed: July 16, 2025

## Official Announcements and Strategic Context

**Red Hat Press Release**  
Red Hat, Inc. *Red Hat launches llm-d community, powering distributed Gen AI inference at scale*. Red Hat Press Releases, 2024.  
<https://www.redhat.com/en/about/press-releases/red-hat-launches-llm-d-community-powering-distributed-gen-ai-inference-scale>  
Accessed: July 16, 2025

## Citation Standards

### Access and Currency

All GitHub repository links reference the most current version available at the time of book publication. Readers should consult the live repositories for the most up-to-date technical specifications and implementation details.

### Version Control

Where specific code examples or configurations are referenced in the book chapters, the corresponding commit SHA or tag version is noted to ensure reproducibility of examples.

### Community Resources

For ongoing community discussions, current issues, and development roadmaps, readers are encouraged to:

- Join the llm-d Slack community
- Participate in weekly contributor standups
- Monitor the GitHub repositories for updates and releases
- Engage with the Google Groups mailing lists

## Acknowledgments

This book's technical accuracy is made possible by the open-source nature of the llm-d project and the comprehensive documentation maintained by the community contributors from CoreWeave, Google, IBM Research, NVIDIA, Red Hat, and the broader ecosystem of partners and academic institutions.

---

*Last updated: July 16, 2025*  
*Next scheduled review: August 16, 2025*
